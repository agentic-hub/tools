{"init_kwargs": {"input_desc": {"properties": {"prompt": {"anyOf": [{"x-order": 5, "title": "Prompt", "temp_default": {}, "displayOptions": {"show": {"resource": ["chat"], "operation": ["complete"]}}, "typeOptions": {"sortable": true, "multipleValues": true}, "displayName": "Prompt", "type": "object", "properties": {"messages": {"title": "Messages", "displayName": "Messages", "type": "array", "items": {"type": "object", "properties": {"content": {"x-order": 1, "title": "Content", "temp_default": "", "displayName": "Content", "type": "string"}, "role": {"x-order": 0, "title": "Role", "temp_default": "user", "default": "user", "displayName": "Role", "enum": ["assistant", "system", "user"]}}, "required": ["content", "role"]}}}}, {"x-order": 9, "description": "A text description of the desired image(s). The maximum length is 1000 characters.", "title": "Prompt", "temp_default": "", "displayOptions": {"show": {"resource": ["image"], "operation": ["create"]}}, "displayName": "Prompt", "type": "string"}, {"x-order": 16, "description": "The prompt to generate completion(s) for", "title": "Prompt", "temp_default": "", "displayOptions": {"show": {"resource": ["text"], "operation": ["complete"]}}, "typeOptions": {"rows": 2}, "displayName": "Prompt", "type": "string"}]}, "credentials": {"type": "object", "ui-type": "collections", "x-order": -10, "properties": {"openAiApi": {"type": "object", "properties": {"id": {"type": "integer"}}}}}, "simplifyOutput": {"anyOf": [{"x-order": 6, "description": "Whether to return a simplified version of the response instead of the raw data", "title": "Simplify", "temp_default": true, "default": true, "displayOptions": {"show": {"operation": ["complete"], "resource": ["chat"]}}, "displayName": "Simplify", "type": "boolean"}, {"x-order": 22, "description": "Whether to return a simplified version of the response instead of the raw data", "title": "Simplify", "temp_default": true, "default": true, "displayOptions": {"show": {"operation": ["moderate"], "resource": ["text"]}}, "displayName": "Simplify", "type": "boolean"}, {"x-order": 23, "description": "Whether to return a simplified version of the response instead of the raw data", "title": "Simplify", "temp_default": true, "default": true, "displayOptions": {"show": {"operation": ["complete", "edit"], "resource": ["text"]}}, "displayName": "Simplify", "type": "boolean"}]}, "input": {"anyOf": [{"x-order": 18, "description": "The input text to be edited", "title": "Input", "temp_default": "", "displayOptions": {"show": {"resource": ["text"], "operation": ["edit"]}}, "displayName": "Input", "type": "string"}, {"x-order": 21, "description": "The input text to classify", "title": "Input", "temp_default": "", "displayOptions": {"show": {"resource": ["text"], "operation": ["moderate"]}}, "displayName": "Input", "type": "string"}]}, "instruction": {"x-order": 19, "description": "The instruction that tells the model how to edit the input text", "title": "Instruction", "temp_default": "", "displayOptions": {"show": {"resource": ["text"], "operation": ["edit"]}}, "displayName": "Instruction", "type": "string"}, "resource": {"x-order": 1, "title": "Resource", "temp_default": "text", "default": "text", "displayName": "Resource", "enum": ["chat", "image", "text", "__CUSTOM_API_CALL__"]}, "imageModel": {"x-order": 11, "description": "The model to use for image generation", "title": "Model", "temp_default": "dall-e-2", "default": "dall-e-2", "displayOptions": {"show": {"resource": ["image"], "operation": ["create"]}, "hide": {"@version": [1]}}, "typeOptions": {"loadOptions": {"routing": {"request": {"method": "GET", "url": "/v1/models"}, "output": {"postReceive": [{"type": "rootProperty", "properties": {"property": "data"}}, {"type": "filter", "properties": {"pass": "={{ $responseItem.id.startsWith('dall-') }}"}}, {"type": "setKeyValue", "properties": {"name": "={{$responseItem.id}}", "value": "={{$responseItem.id}}"}}, {"type": "sort", "properties": {"key": "name"}}]}}}}, "displayName": "Model", "enum": []}, "options": {"anyOf": [{"x-order": 7, "description": "Additional options to add", "title": "Options", "temp_default": {}, "displayOptions": {"show": {"operation": ["complete"], "resource": ["chat"]}}, "displayName": "Options", "type": "object", "ui-type": "collections", "properties": {"topP": {"x-order": 6, "description": "Controls diversity via nucleus sampling: 0.5 means half of all likelihood-weighted options are considered. We generally recommend altering this or temperature but not both.", "title": "Top P", "temp_default": 1, "default": 1, "typeOptions": {"maxValue": 1, "minValue": 0, "numberPrecision": 1}, "displayName": "Top P", "type": "number", "minimum": 0, "maximum": 1}, "presence_penalty": {"x-order": 4, "description": "Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics", "title": "Presence Penalty", "temp_default": 0, "typeOptions": {"maxValue": 2, "minValue": -2, "numberPrecision": 1}, "displayName": "Presence Penalty", "type": "number", "minimum": -2, "maximum": 2}, "temperature": {"x-order": 5, "description": "Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.", "title": "Sampling Temperature", "temp_default": 1, "default": 1, "typeOptions": {"maxValue": 1, "minValue": 0, "numberPrecision": 1}, "displayName": "Sampling Temperature", "type": "number", "minimum": 0, "maximum": 1}, "maxTokens": {"x-order": 2, "description": "The maximum number of tokens to generate in the completion. Most models have a context length of 2048 tokens (except for the newest models, which support 32,768).", "title": "Maximum Number of Tokens", "temp_default": 16, "default": 16, "displayOptions": {"show": {"/operation": ["complete"]}}, "typeOptions": {"maxValue": 32768}, "displayName": "Maximum Number of Tokens", "type": "number", "maximum": 32768}, "echo": {"x-order": 0, "description": "Whether the prompt should be echo back in addition to the completion", "title": "Echo Prompt", "temp_default": false, "default": false, "displayOptions": {"show": {"/operation": ["complete"]}}, "displayName": "Echo Prompt", "type": "boolean"}, "frequency_penalty": {"x-order": 1, "description": "Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim", "title": "Frequency Penalty", "temp_default": 0, "typeOptions": {"maxValue": 2, "minValue": -2, "numberPrecision": 1}, "displayName": "Frequency Penalty", "type": "number", "minimum": -2, "maximum": 2}, "n": {"x-order": 3, "description": "How many completions to generate for each prompt. Note: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for max_tokens and stop.", "title": "Number of Completions", "temp_default": 1, "default": 1, "displayName": "Number of Completions", "type": "number"}}, "required": []}, {"x-order": 13, "description": "Additional options to add", "title": "Options", "temp_default": {}, "displayOptions": {"show": {"resource": ["image"], "operation": ["create"]}}, "displayName": "Options", "type": "object", "ui-type": "collections", "properties": {"size": {"anyOf": [{"x-order": 2, "title": "Resolution", "temp_default": "1024x1024", "default": "1024x1024", "displayOptions": {"show": {"/model": ["dall-e-2"]}}, "displayName": "Resolution", "enum": ["256x256", "512x512", "1024x1024"]}, {"x-order": 3, "title": "Resolution", "temp_default": "1024x1024", "default": "1024x1024", "displayOptions": {"show": {"/model": ["dall-e-3"]}}, "displayName": "Resolution", "enum": ["1024x1024", "1792x1024", "1024x1792"]}]}, "quality": {"x-order": 1, "title": "Quality", "temp_default": "standard", "default": "standard", "displayOptions": {"show": {"/model": ["dall-e-3"]}}, "displayName": "Quality", "enum": ["hd", "standard"]}, "n": {"x-order": 0, "description": "Number of images to generate", "title": "Number of Images", "temp_default": 1, "default": 1, "typeOptions": {"minValue": 1, "maxValue": 10}, "displayName": "Number of Images", "type": "number", "minimum": 1, "maximum": 10}, "style": {"x-order": 4, "title": "Style", "temp_default": "vivid", "default": "vivid", "displayOptions": {"show": {"/model": ["dall-e-3"]}}, "displayName": "Style", "enum": ["natural", "vivid"]}}, "required": []}, {"x-order": 24, "description": "Additional options to add", "title": "Options", "temp_default": {}, "displayOptions": {"show": {"operation": ["complete", "edit"], "resource": ["text"]}}, "displayName": "Options", "type": "object", "ui-type": "collections", "properties": {"topP": {"x-order": 6, "description": "Controls diversity via nucleus sampling: 0.5 means half of all likelihood-weighted options are considered. We generally recommend altering this or temperature but not both.", "title": "Top P", "temp_default": 1, "default": 1, "typeOptions": {"maxValue": 1, "minValue": 0, "numberPrecision": 1}, "displayName": "Top P", "type": "number", "minimum": 0, "maximum": 1}, "presence_penalty": {"x-order": 4, "description": "Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics", "title": "Presence Penalty", "temp_default": 0, "typeOptions": {"maxValue": 2, "minValue": -2, "numberPrecision": 1}, "displayName": "Presence Penalty", "type": "number", "minimum": -2, "maximum": 2}, "temperature": {"x-order": 5, "description": "Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.", "title": "Sampling Temperature", "temp_default": 1, "default": 1, "typeOptions": {"maxValue": 1, "minValue": 0, "numberPrecision": 1}, "displayName": "Sampling Temperature", "type": "number", "minimum": 0, "maximum": 1}, "maxTokens": {"x-order": 2, "description": "The maximum number of tokens to generate in the completion. Most models have a context length of 2048 tokens (except for the newest models, which support 32,768).", "title": "Maximum Number of Tokens", "temp_default": 16, "default": 16, "displayOptions": {"show": {"/operation": ["complete"]}}, "typeOptions": {"maxValue": 32768}, "displayName": "Maximum Number of Tokens", "type": "number", "maximum": 32768}, "echo": {"x-order": 0, "description": "Whether the prompt should be echo back in addition to the completion", "title": "Echo Prompt", "temp_default": false, "default": false, "displayOptions": {"show": {"/operation": ["complete"]}}, "displayName": "Echo Prompt", "type": "boolean"}, "frequency_penalty": {"x-order": 1, "description": "Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim", "title": "Frequency Penalty", "temp_default": 0, "typeOptions": {"maxValue": 2, "minValue": -2, "numberPrecision": 1}, "displayName": "Frequency Penalty", "type": "number", "minimum": -2, "maximum": 2}, "n": {"x-order": 3, "description": "How many completions to generate for each prompt. Note: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for max_tokens and stop.", "title": "Number of Completions", "temp_default": 1, "default": 1, "displayName": "Number of Completions", "type": "number"}}, "required": []}]}, "model": {"anyOf": [{"x-order": 3, "description": "The model which will generate the completion. <a href=\"https://beta.openai.com/docs/models/overview\">Learn more</a>.", "title": "Model", "temp_default": "gpt-3.5-turbo", "default": "gpt-3.5-turbo", "displayOptions": {"show": {"operation": ["complete"], "resource": ["chat"], "@version": [1]}}, "typeOptions": {"loadOptions": {"routing": {"request": {"method": "GET", "url": "/v1/models"}, "output": {"postReceive": [{"type": "rootProperty", "properties": {"property": "data"}}, {"type": "filter", "properties": {"pass": "={{ $responseItem.id.startsWith('gpt-') && !$responseItem.id.startsWith('gpt-4-vision') }}"}}, {"type": "setKeyValue", "properties": {"name": "={{$responseItem.id}}", "value": "={{$responseItem.id}}"}}, {"type": "sort", "properties": {"key": "name"}}]}}}}, "displayName": "Model", "enum": []}, {"x-order": 10, "description": "The model to use for image generation", "title": "Model", "temp_default": "dall-e-2", "default": "dall-e-2", "displayOptions": {"show": {"resource": ["image"], "operation": ["create"], "@version": [1]}}, "typeOptions": {"loadOptions": {"routing": {"request": {"method": "GET", "url": "/v1/models"}, "output": {"postReceive": [{"type": "rootProperty", "properties": {"property": "data"}}, {"type": "filter", "properties": {"pass": "={{ $responseItem.id.startsWith('dall-') }}"}}, {"type": "setKeyValue", "properties": {"name": "={{$responseItem.id}}", "value": "={{$responseItem.id}}"}}, {"type": "sort", "properties": {"key": "name"}}]}}}}, "displayName": "Model", "enum": []}, {"x-order": 15, "description": "The model which will generate the completion. <a href=\"https://beta.openai.com/docs/models/overview\">Learn more</a>.", "title": "Model", "temp_default": "gpt-3.5-turbo-instruct", "default": "gpt-3.5-turbo-instruct", "displayOptions": {"show": {"operation": ["complete"], "resource": ["text"]}}, "typeOptions": {"loadOptions": {"routing": {"request": {"method": "GET", "url": "/v1/models"}, "output": {"postReceive": [{"type": "rootProperty", "properties": {"property": "data"}}, {"type": "filter", "properties": {"pass": "={{ !$responseItem.id.startsWith('audio-') && ($responseItem.id === 'gpt-3.5-turbo-instruct' || !$responseItem.id.startsWith('gpt-') ) && !$responseItem.id.startsWith('dall-') && !$responseItem.id.startsWith('tts-') && !$responseItem.id.startsWith('whisper-') && !['cushman:2020-05-03', 'davinci-if:3.0.0', 'davinci-instruct-beta:2.0.0', 'if'].includes($responseItem.id) && !$responseItem.id.includes('-edit-') && !$responseItem.id.endsWith(':001') }}"}}, {"type": "setKeyValue", "properties": {"name": "={{$responseItem.id}}", "value": "={{$responseItem.id}}"}}, {"type": "sort", "properties": {"key": "name"}}]}}}}, "displayName": "Model", "enum": []}, {"x-order": 17, "description": "The model which will generate the edited version. <a href=\"https://beta.openai.com/docs/models/overview\">Learn more</a>.", "title": "Model", "temp_default": "text-davinci-edit-001", "default": "text-davinci-edit-001", "displayOptions": {"show": {"operation": ["edit"], "resource": ["text"]}}, "displayName": "Model", "enum": ["code-davinci-edit-001", "text-davinci-edit-001"]}, {"x-order": 20, "description": "The model which will classify the text. <a href=\"https://beta.openai.com/docs/models/overview\">Learn more</a>.", "title": "Model", "temp_default": "text-moderation-latest", "default": "text-moderation-latest", "displayOptions": {"show": {"resource": ["text"], "operation": ["moderate"]}}, "displayName": "Model", "enum": ["text-moderation-stable", "text-moderation-latest"]}]}, "noticeAdvanceAi": {"x-order": 0, "title": "For more advanced uses, consider using an <a data-action=\"openSelectiveNodeCreator\" data-action-parameter-creatorview=\"AI\">advanced AI</a> node", "temp_default": "", "displayName": "For more advanced uses, consider using an <a data-action=\"openSelectiveNodeCreator\" data-action-parameter-creatorview=\"AI\">advanced AI</a> node", "type": "string", "ui-type": "notice"}, "load_files": {"title": "Load files to context", "x-order": -5, "type": "array", "items": {"title": "File info", "type": "object", "properties": {"url": {"title": "Url", "type": "string", "format": "uri", "displayOptions": {"show": {"group": ["url"]}}}, "base": {"title": "Bytes", "type": "string", "displayOptions": {"show": {"group": ["base"]}}}, "name": {"title": "Context filename", "type": "string", "default": "data"}, "group": {"type": "string", "default": "url", "enum": ["url", "base"]}}}}, "operation": {"anyOf": [{"x-order": 2, "title": "Operation", "temp_default": "complete", "default": "complete", "displayOptions": {"show": {"resource": ["chat"]}}, "displayName": "Operation", "enum": ["complete", "__CUSTOM_API_CALL__"]}, {"x-order": 8, "title": "Operation", "temp_default": "create", "default": "create", "displayOptions": {"show": {"resource": ["image"]}}, "displayName": "Operation", "enum": ["create", "__CUSTOM_API_CALL__"]}, {"x-order": 14, "title": "Operation", "temp_default": "complete", "default": "complete", "displayOptions": {"show": {"resource": ["text"]}}, "displayName": "Operation", "enum": ["complete", "edit", "moderate", "__CUSTOM_API_CALL__"]}]}, "responseFormat": {"x-order": 12, "description": "The format in which to return the image(s)", "title": "Response Format", "temp_default": "binaryData", "default": "binaryData", "displayOptions": {"show": {"resource": ["image"], "operation": ["create"]}}, "displayName": "Response Format", "enum": ["binaryData", "imageUrl"]}, "chatModel": {"x-order": 4, "description": "The model which will generate the completion. <a href=\"https://beta.openai.com/docs/models/overview\">Learn more</a>.", "title": "Model", "temp_default": "gpt-3.5-turbo", "default": "gpt-3.5-turbo", "displayOptions": {"show": {"operation": ["complete"], "resource": ["chat"]}, "hide": {"@version": [1]}}, "typeOptions": {"loadOptions": {"routing": {"request": {"method": "GET", "url": "/v1/models"}, "output": {"postReceive": [{"type": "rootProperty", "properties": {"property": "data"}}, {"type": "filter", "properties": {"pass": "={{ $responseItem.id.startsWith('gpt-') && !$responseItem.id.startsWith('gpt-4-vision') }}"}}, {"type": "setKeyValue", "properties": {"name": "={{$responseItem.id}}", "value": "={{$responseItem.id}}"}}, {"type": "sort", "properties": {"key": "name"}}]}}}}, "displayName": "Model", "enum": []}}, "required": [], "title": "Input", "type": "object"}, "title": "Scade tools: OpenAI", "description": "Consume Open AI", "scade_tools_node_name": "scade-tools-nodes-base.openAi", "scade_tools_node_version": 1, "categories": ["Utility"]}, "class_name": "ScadeToolsProcessor", "license_url": null}